[
  {
    "objectID": "slides/07-wrapping-up.html#resources-to-keep-learning",
    "href": "slides/07-wrapping-up.html#resources-to-keep-learning",
    "title": "7 - Wrapping up",
    "section": "Resources to keep learning",
    "text": "Resources to keep learning\n\n\nhttps://www.tidymodels.org/\n\n\n\n\nhttps://www.tmwr.org/\n\n\n\n\nhttp://www.feat.engineering/\n\n\n\n\nhttps://smltar.com/\n\n\n\nFollow us on Twitter and at the tidyverse blog for updates!"
  },
  {
    "objectID": "slides/04-evaluating-models.html#metrics-for-model-performance",
    "href": "slides/04-evaluating-models.html#metrics-for-model-performance",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\n\n\n\naugment(tree_fit, new_data = frog_test) %>%\n  metrics(latency, .pred)\n#> # A tibble: 3 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      59.2  \n#> 2 rsq     standard       0.380\n#> 3 mae     standard      40.2\n\n\n\nRMSE: difference between the predicted and observed values ⬇️\n\\(R^2\\): squared correlation between the predicted and observed values ⬆️\nMAE: similar to RMSE, but mean absolute error ⬇️"
  },
  {
    "objectID": "slides/04-evaluating-models.html#metrics-for-model-performance-1",
    "href": "slides/04-evaluating-models.html#metrics-for-model-performance-1",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\naugment(tree_fit, new_data = frog_test) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        59.2"
  },
  {
    "objectID": "slides/04-evaluating-models.html#metrics-for-model-performance-2",
    "href": "slides/04-evaluating-models.html#metrics-for-model-performance-2",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\naugment(tree_fit, new_data = frog_test) %>%\n  group_by(reflex) %>%\n  rmse(latency, .pred)\n#> # A tibble: 3 × 4\n#>   reflex .metric .estimator .estimate\n#>   <fct>  <chr>   <chr>          <dbl>\n#> 1 low    rmse    standard        94.3\n#> 2 mid    rmse    standard       101. \n#> 3 full   rmse    standard        51.2"
  },
  {
    "objectID": "slides/04-evaluating-models.html#metrics-for-model-performance-3",
    "href": "slides/04-evaluating-models.html#metrics-for-model-performance-3",
    "title": "4 - Evaluating models",
    "section": "Metrics for model performance ",
    "text": "Metrics for model performance \n\nfrog_metrics <- metric_set(rmse, msd)\naugment(tree_fit, new_data = frog_test) %>%\n  frog_metrics(latency, .pred)\n#> # A tibble: 2 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      59.2  \n#> 2 msd     standard      -0.908"
  },
  {
    "objectID": "slides/04-evaluating-models.html#dangers-of-overfitting-1",
    "href": "slides/04-evaluating-models.html#dangers-of-overfitting-1",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting ⚠️",
    "text": "Dangers of overfitting ⚠️"
  },
  {
    "objectID": "slides/04-evaluating-models.html#dangers-of-overfitting-2",
    "href": "slides/04-evaluating-models.html#dangers-of-overfitting-2",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting ⚠️",
    "text": "Dangers of overfitting ⚠️"
  },
  {
    "objectID": "slides/04-evaluating-models.html#dangers-of-overfitting-3",
    "href": "slides/04-evaluating-models.html#dangers-of-overfitting-3",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting ⚠️ ",
    "text": "Dangers of overfitting ⚠️ \n\ntree_fit %>%\n  augment(frog_train)\n#> # A tibble: 456 × 6\n#>    treatment  reflex    age t_o_d     latency .pred\n#>    <chr>      <fct>   <dbl> <fct>       <dbl> <dbl>\n#>  1 control    full   467950 morning        33  39.8\n#>  2 control    full   464870 morning        19  66.7\n#>  3 control    full   464610 morning         2  66.7\n#>  4 control    full   469650 morning        39  39.8\n#>  5 control    full   467600 morning        42  39.8\n#>  6 control    full   410460 afternoon      20  59.8\n#>  7 control    full   427685 night          31  83.1\n#>  8 control    full   468530 morning        21  39.8\n#>  9 gentamicin full   465800 morning        30  64.6\n#> 10 control    full   393475 afternoon      43 174. \n#> # … with 446 more rows\n\nWe call this “resubstition” or “repredicting the training set”"
  },
  {
    "objectID": "slides/04-evaluating-models.html#dangers-of-overfitting-4",
    "href": "slides/04-evaluating-models.html#dangers-of-overfitting-4",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting ⚠️ ",
    "text": "Dangers of overfitting ⚠️ \n\ntree_fit %>%\n  augment(frog_train) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        49.4\n\nWe call this a “resubstition metric”"
  },
  {
    "objectID": "slides/04-evaluating-models.html#dangers-of-overfitting-5",
    "href": "slides/04-evaluating-models.html#dangers-of-overfitting-5",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting ⚠️ ",
    "text": "Dangers of overfitting ⚠️ \n\n\n\ntree_fit %>%\n  augment(frog_train) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        49.4"
  },
  {
    "objectID": "slides/04-evaluating-models.html#dangers-of-overfitting-6",
    "href": "slides/04-evaluating-models.html#dangers-of-overfitting-6",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting ⚠️ ",
    "text": "Dangers of overfitting ⚠️ \n\n\n\ntree_fit %>%\n  augment(frog_train) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        49.4\n\n\n\ntree_fit %>%\n  augment(frog_test) %>%\n  rmse(latency, .pred)\n#> # A tibble: 1 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard        59.2\n\n\n\n\n⚠️ Remember that we’re demonstrating overfitting\n\n\n⚠️ Don’t use the test set until the end of your modeling analysis"
  },
  {
    "objectID": "slides/04-evaluating-models.html#your-turn",
    "href": "slides/04-evaluating-models.html#your-turn",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nUse augment() and metrics() to compute regression metrics.\nCompute the metrics for both training and testing data.\nNotice the evidence of overfitting! ⚠️\n\n\n\n05:00"
  },
  {
    "objectID": "slides/04-evaluating-models.html#dangers-of-overfitting-7",
    "href": "slides/04-evaluating-models.html#dangers-of-overfitting-7",
    "title": "4 - Evaluating models",
    "section": "Dangers of overfitting ⚠️ ",
    "text": "Dangers of overfitting ⚠️ \n\n\n\ntree_fit %>%\n  augment(frog_train) %>%\n  metrics(latency, .pred)\n#> # A tibble: 3 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      49.4  \n#> 2 rsq     standard       0.494\n#> 3 mae     standard      33.4\n\n\n\ntree_fit %>%\n  augment(frog_test) %>%\n  metrics(latency, .pred)\n#> # A tibble: 3 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard      59.2  \n#> 2 rsq     standard       0.380\n#> 3 mae     standard      40.2\n\n\n\n\nWhat if we want to compare more models?\n\n\nAnd/or more model configurations?\n\n\nAnd we want to understand if these are important differences?"
  },
  {
    "objectID": "slides/04-evaluating-models.html#cross-validation",
    "href": "slides/04-evaluating-models.html#cross-validation",
    "title": "4 - Evaluating models",
    "section": "Cross-validation",
    "text": "Cross-validation"
  },
  {
    "objectID": "slides/04-evaluating-models.html#cross-validation-1",
    "href": "slides/04-evaluating-models.html#cross-validation-1",
    "title": "4 - Evaluating models",
    "section": "Cross-validation",
    "text": "Cross-validation"
  },
  {
    "objectID": "slides/04-evaluating-models.html#your-turn-1",
    "href": "slides/04-evaluating-models.html#your-turn-1",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nIf we use 10 folds, what percent of the training data\n\nends up in analysis\nends up in assessment\n\nfor each fold?\n\n\n\n\n03:00"
  },
  {
    "objectID": "slides/04-evaluating-models.html#resampling",
    "href": "slides/04-evaluating-models.html#resampling",
    "title": "4 - Evaluating models",
    "section": "Resampling ",
    "text": "Resampling \n\nvfold_cv(frog_train) ## v = 10 is default\n#> #  10-fold cross-validation \n#> # A tibble: 10 × 2\n#>    splits           id    \n#>    <list>           <chr> \n#>  1 <split [410/46]> Fold01\n#>  2 <split [410/46]> Fold02\n#>  3 <split [410/46]> Fold03\n#>  4 <split [410/46]> Fold04\n#>  5 <split [410/46]> Fold05\n#>  6 <split [410/46]> Fold06\n#>  7 <split [411/45]> Fold07\n#>  8 <split [411/45]> Fold08\n#>  9 <split [411/45]> Fold09\n#> 10 <split [411/45]> Fold10"
  },
  {
    "objectID": "slides/04-evaluating-models.html#resampling-1",
    "href": "slides/04-evaluating-models.html#resampling-1",
    "title": "4 - Evaluating models",
    "section": "Resampling ",
    "text": "Resampling \n\nvfold_cv(frog_train, v = 5)\n#> #  5-fold cross-validation \n#> # A tibble: 5 × 2\n#>   splits           id   \n#>   <list>           <chr>\n#> 1 <split [364/92]> Fold1\n#> 2 <split [365/91]> Fold2\n#> 3 <split [365/91]> Fold3\n#> 4 <split [365/91]> Fold4\n#> 5 <split [365/91]> Fold5"
  },
  {
    "objectID": "slides/04-evaluating-models.html#resampling-2",
    "href": "slides/04-evaluating-models.html#resampling-2",
    "title": "4 - Evaluating models",
    "section": "Resampling ",
    "text": "Resampling \nWhat is in this?\n\nfrog_folds <- vfold_cv(frog_train, v = 10)\nfrog_folds$splits[1:3]\n#> [[1]]\n#> <Analysis/Assess/Total>\n#> <410/46/456>\n#> \n#> [[2]]\n#> <Analysis/Assess/Total>\n#> <410/46/456>\n#> \n#> [[3]]\n#> <Analysis/Assess/Total>\n#> <410/46/456>\n\n\nTalk about a list column, storing non-atomic types in dataframe"
  },
  {
    "objectID": "slides/04-evaluating-models.html#bootstrapping",
    "href": "slides/04-evaluating-models.html#bootstrapping",
    "title": "4 - Evaluating models",
    "section": "Bootstrapping",
    "text": "Bootstrapping"
  },
  {
    "objectID": "slides/04-evaluating-models.html#resampling-3",
    "href": "slides/04-evaluating-models.html#resampling-3",
    "title": "4 - Evaluating models",
    "section": "Resampling ",
    "text": "Resampling \n\nbootstraps(frog_train)\n#> # Bootstrap sampling \n#> # A tibble: 25 × 2\n#>    splits            id         \n#>    <list>            <chr>      \n#>  1 <split [456/159]> Bootstrap01\n#>  2 <split [456/168]> Bootstrap02\n#>  3 <split [456/175]> Bootstrap03\n#>  4 <split [456/176]> Bootstrap04\n#>  5 <split [456/162]> Bootstrap05\n#>  6 <split [456/169]> Bootstrap06\n#>  7 <split [456/161]> Bootstrap07\n#>  8 <split [456/169]> Bootstrap08\n#>  9 <split [456/177]> Bootstrap09\n#> 10 <split [456/174]> Bootstrap10\n#> # … with 15 more rows"
  },
  {
    "objectID": "slides/04-evaluating-models.html#your-turn-2",
    "href": "slides/04-evaluating-models.html#your-turn-2",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nCreate:\n\ncross-validation folds with stratification\nbootstrap folds (change times from the default)\nvalidation resample\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/04-evaluating-models.html#resampling-4",
    "href": "slides/04-evaluating-models.html#resampling-4",
    "title": "4 - Evaluating models",
    "section": "Resampling ",
    "text": "Resampling \n\nvfold_cv(frog_train, strata = latency)\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 × 2\n#>    splits           id    \n#>    <list>           <chr> \n#>  1 <split [408/48]> Fold01\n#>  2 <split [408/48]> Fold02\n#>  3 <split [408/48]> Fold03\n#>  4 <split [409/47]> Fold04\n#>  5 <split [411/45]> Fold05\n#>  6 <split [412/44]> Fold06\n#>  7 <split [412/44]> Fold07\n#>  8 <split [412/44]> Fold08\n#>  9 <split [412/44]> Fold09\n#> 10 <split [412/44]> Fold10\n\n\nStratification often helps, with very little downside"
  },
  {
    "objectID": "slides/04-evaluating-models.html#resampling-5",
    "href": "slides/04-evaluating-models.html#resampling-5",
    "title": "4 - Evaluating models",
    "section": "Resampling ",
    "text": "Resampling \n\nbootstraps(frog_train, times = 10)\n#> # Bootstrap sampling \n#> # A tibble: 10 × 2\n#>    splits            id         \n#>    <list>            <chr>      \n#>  1 <split [456/162]> Bootstrap01\n#>  2 <split [456/165]> Bootstrap02\n#>  3 <split [456/159]> Bootstrap03\n#>  4 <split [456/169]> Bootstrap04\n#>  5 <split [456/168]> Bootstrap05\n#>  6 <split [456/171]> Bootstrap06\n#>  7 <split [456/175]> Bootstrap07\n#>  8 <split [456/168]> Bootstrap08\n#>  9 <split [456/166]> Bootstrap09\n#> 10 <split [456/156]> Bootstrap10"
  },
  {
    "objectID": "slides/04-evaluating-models.html#resampling-6",
    "href": "slides/04-evaluating-models.html#resampling-6",
    "title": "4 - Evaluating models",
    "section": "Resampling ",
    "text": "Resampling \n\nvalidation_split(frog_train, strata = latency)\n#> # Validation Set Split (0.75/0.25)  using stratification \n#> # A tibble: 1 × 2\n#>   splits            id        \n#>   <list>            <chr>     \n#> 1 <split [340/116]> validation\n\n\nA validation split is just another type of resample"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluating-model-performance",
    "href": "slides/04-evaluating-models.html#evaluating-model-performance",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nset.seed(123)\nfrog_folds <- vfold_cv(frog_train, v = 10, strata = latency)\nfrog_folds\n#> #  10-fold cross-validation using stratification \n#> # A tibble: 10 × 2\n#>    splits           id    \n#>    <list>           <chr> \n#>  1 <split [408/48]> Fold01\n#>  2 <split [408/48]> Fold02\n#>  3 <split [408/48]> Fold03\n#>  4 <split [409/47]> Fold04\n#>  5 <split [411/45]> Fold05\n#>  6 <split [412/44]> Fold06\n#>  7 <split [412/44]> Fold07\n#>  8 <split [412/44]> Fold08\n#>  9 <split [412/44]> Fold09\n#> 10 <split [412/44]> Fold10\n\n\nSet the seed when creating resamples"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluating-model-performance-1",
    "href": "slides/04-evaluating-models.html#evaluating-model-performance-1",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nfit_resamples(tree_wflow, frog_folds)\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 × 4\n#>    splits           id     .metrics         .notes          \n#>    <list>           <chr>  <list>           <list>          \n#>  1 <split [408/48]> Fold01 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  2 <split [408/48]> Fold02 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  3 <split [408/48]> Fold03 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  4 <split [409/47]> Fold04 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  5 <split [411/45]> Fold05 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  6 <split [412/44]> Fold06 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  7 <split [412/44]> Fold07 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  8 <split [412/44]> Fold08 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  9 <split [412/44]> Fold09 <tibble [2 × 4]> <tibble [0 × 3]>\n#> 10 <split [412/44]> Fold10 <tibble [2 × 4]> <tibble [0 × 3]>\n\n\nWhere are the fitted models??!??"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluating-model-performance-2",
    "href": "slides/04-evaluating-models.html#evaluating-model-performance-2",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nfit_resamples(tree_wflow, frog_folds)\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 × 4\n#>    splits           id     .metrics         .notes          \n#>    <list>           <chr>  <list>           <list>          \n#>  1 <split [408/48]> Fold01 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  2 <split [408/48]> Fold02 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  3 <split [408/48]> Fold03 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  4 <split [409/47]> Fold04 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  5 <split [411/45]> Fold05 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  6 <split [412/44]> Fold06 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  7 <split [412/44]> Fold07 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  8 <split [412/44]> Fold08 <tibble [2 × 4]> <tibble [0 × 3]>\n#>  9 <split [412/44]> Fold09 <tibble [2 × 4]> <tibble [0 × 3]>\n#> 10 <split [412/44]> Fold10 <tibble [2 × 4]> <tibble [0 × 3]>\n\nWhere are the fitted models??!?? 🗑️\n\nFor more advanced use cases, you can extract and save them: https://www.tmwr.org/resampling.html#extract"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluating-model-performance-3",
    "href": "slides/04-evaluating-models.html#evaluating-model-performance-3",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nfit_resamples(tree_wflow, frog_folds) %>%\n  collect_metrics()\n#> # A tibble: 2 × 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 rmse    standard   59.6      10  2.31   Preprocessor1_Model1\n#> 2 rsq     standard    0.305    10  0.0342 Preprocessor1_Model1\n\n\nWe can reliably measure performance using only the training data 🎉"
  },
  {
    "objectID": "slides/04-evaluating-models.html#embarrassingly-parallel",
    "href": "slides/04-evaluating-models.html#embarrassingly-parallel",
    "title": "4 - Evaluating models",
    "section": "Embarrassingly parallel ",
    "text": "Embarrassingly parallel \n\ndoParallel::registerDoParallel()\n\n# Save the assessment set results\nctrl_frog <- control_resamples(save_pred = TRUE)\n\nset.seed(1)\ntree_res <- fit_resamples(tree_wflow, frog_folds, control = ctrl_frog)\n\ntree_res %>% collect_metrics()\n#> # A tibble: 2 × 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 rmse    standard   59.6      10  2.31   Preprocessor1_Model1\n#> 2 rsq     standard    0.305    10  0.0342 Preprocessor1_Model1\n\n\nEach fit is independent of the others"
  },
  {
    "objectID": "slides/04-evaluating-models.html#comparing-metrics",
    "href": "slides/04-evaluating-models.html#comparing-metrics",
    "title": "4 - Evaluating models",
    "section": "Comparing metrics ",
    "text": "Comparing metrics \nHow do the metrics from resampling compare to the metrics from training and testing?\n\n\n\n\n\n\ntree_res %>%\n  collect_metrics() %>% \n  select(.metric, mean, n)\n#> # A tibble: 2 × 3\n#>   .metric   mean     n\n#>   <chr>    <dbl> <int>\n#> 1 rmse    59.6      10\n#> 2 rsq      0.305    10\n\n\nThe RMSE previously was\n\n49.36 for the training set\n59.16 for test set\n\n\n\n\nRemember that:\n⚠️ the training set gives you overly optimistic metrics\n⚠️ the test set is precious"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluating-model-performance-4",
    "href": "slides/04-evaluating-models.html#evaluating-model-performance-4",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nctrl_frog <- control_resamples(save_pred = TRUE)\n\ntree_preds <- \n  tree_res %>%\n  collect_predictions()\n\ntree_preds\n#> # A tibble: 456 × 5\n#>    id     .pred  .row latency .config             \n#>    <chr>  <dbl> <int>   <dbl> <chr>               \n#>  1 Fold01  39.6     1      33 Preprocessor1_Model1\n#>  2 Fold01  72.1     3       2 Preprocessor1_Model1\n#>  3 Fold01  63.8     9      30 Preprocessor1_Model1\n#>  4 Fold01  72.1    13      46 Preprocessor1_Model1\n#>  5 Fold01  43.3    28      11 Preprocessor1_Model1\n#>  6 Fold01  61.7    35      41 Preprocessor1_Model1\n#>  7 Fold01  39.6    51      43 Preprocessor1_Model1\n#>  8 Fold01 134.     70      20 Preprocessor1_Model1\n#>  9 Fold01  70.6    74      21 Preprocessor1_Model1\n#> 10 Fold01  39.6   106      14 Preprocessor1_Model1\n#> # … with 446 more rows"
  },
  {
    "objectID": "slides/04-evaluating-models.html#section-4",
    "href": "slides/04-evaluating-models.html#section-4",
    "title": "4 - Evaluating models",
    "section": "",
    "text": "tree_preds %>% \n  ggplot(aes(latency, .pred, color = id)) + \n  geom_abline(lty = 2, col = \"gray\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  coord_obs_pred()"
  },
  {
    "objectID": "slides/04-evaluating-models.html#random-forest-1",
    "href": "slides/04-evaluating-models.html#random-forest-1",
    "title": "4 - Evaluating models",
    "section": "Random forest 🌳🌲🌴🌵🌳🌳🌴🌲🌵🌴🌳🌵",
    "text": "Random forest 🌳🌲🌴🌵🌳🌳🌴🌲🌵🌴🌳🌵\n\nEnsemble many decision tree models\nAll the trees vote! 🗳️\nBootstrap aggregating + random feature selection\n\n\n\nOften works well without tuning hyperparameters (more on this tomorrow!), as long as there are enough trees"
  },
  {
    "objectID": "slides/04-evaluating-models.html#create-a-random-forest-model",
    "href": "slides/04-evaluating-models.html#create-a-random-forest-model",
    "title": "4 - Evaluating models",
    "section": "Create a random forest model ",
    "text": "Create a random forest model \n\nrf_spec <- rand_forest(trees = 1000, mode = \"regression\")\nrf_spec\n#> Random Forest Model Specification (regression)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger"
  },
  {
    "objectID": "slides/04-evaluating-models.html#create-a-random-forest-model-1",
    "href": "slides/04-evaluating-models.html#create-a-random-forest-model-1",
    "title": "4 - Evaluating models",
    "section": "Create a random forest model ",
    "text": "Create a random forest model \n\nrf_wflow <- workflow(latency ~ ., rf_spec)\nrf_wflow\n#> ══ Workflow ══════════════════════════════════════════════════════════\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> ── Preprocessor ──────────────────────────────────────────────────────\n#> latency ~ .\n#> \n#> ── Model ─────────────────────────────────────────────────────────────\n#> Random Forest Model Specification (regression)\n#> \n#> Main Arguments:\n#>   trees = 1000\n#> \n#> Computational engine: ranger"
  },
  {
    "objectID": "slides/04-evaluating-models.html#your-turn-3",
    "href": "slides/04-evaluating-models.html#your-turn-3",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nUse fit_resamples() and rf_wflow to:\n\nkeep predictions\ncompute metrics\nplot true vs. predicted values\n\n\n\n\n05:00"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluating-model-performance-5",
    "href": "slides/04-evaluating-models.html#evaluating-model-performance-5",
    "title": "4 - Evaluating models",
    "section": "Evaluating model performance ",
    "text": "Evaluating model performance \n\nctrl_frog <- control_resamples(save_pred = TRUE)\n\n# Random forest uses random numbers so set the seed first\n\nset.seed(2)\nrf_res <- fit_resamples(rf_wflow, frog_folds, control = ctrl_frog)\ncollect_metrics(rf_res)\n#> # A tibble: 2 × 6\n#>   .metric .estimator   mean     n std_err .config             \n#>   <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n#> 1 rmse    standard   55.9      10  1.71   Preprocessor1_Model1\n#> 2 rsq     standard    0.370    10  0.0306 Preprocessor1_Model1"
  },
  {
    "objectID": "slides/04-evaluating-models.html#section-5",
    "href": "slides/04-evaluating-models.html#section-5",
    "title": "4 - Evaluating models",
    "section": "",
    "text": "collect_predictions(rf_res) %>% \n  ggplot(aes(latency, .pred, color = id)) + \n  geom_abline(lty = 2, col = \"gray\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  coord_obs_pred()"
  },
  {
    "objectID": "slides/04-evaluating-models.html#how-can-we-compare-multiple-model-workflows-at-once",
    "href": "slides/04-evaluating-models.html#how-can-we-compare-multiple-model-workflows-at-once",
    "title": "4 - Evaluating models",
    "section": "How can we compare multiple model workflows at once?",
    "text": "How can we compare multiple model workflows at once?"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluate-a-workflow-set",
    "href": "slides/04-evaluating-models.html#evaluate-a-workflow-set",
    "title": "4 - Evaluating models",
    "section": "Evaluate a workflow set",
    "text": "Evaluate a workflow set\n\nworkflow_set(list(latency ~ .), list(tree_spec, rf_spec))\n#> # A workflow set/tibble: 2 × 4\n#>   wflow_id              info             option    result    \n#>   <chr>                 <list>           <list>    <list>    \n#> 1 formula_decision_tree <tibble [1 × 4]> <opts[0]> <list [0]>\n#> 2 formula_rand_forest   <tibble [1 × 4]> <opts[0]> <list [0]>"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluate-a-workflow-set-1",
    "href": "slides/04-evaluating-models.html#evaluate-a-workflow-set-1",
    "title": "4 - Evaluating models",
    "section": "Evaluate a workflow set",
    "text": "Evaluate a workflow set\n\nworkflow_set(list(latency ~ .), list(tree_spec, rf_spec)) %>%\n  workflow_map(\"fit_resamples\", resamples = frog_folds)\n#> # A workflow set/tibble: 2 × 4\n#>   wflow_id              info             option    result   \n#>   <chr>                 <list>           <list>    <list>   \n#> 1 formula_decision_tree <tibble [1 × 4]> <opts[1]> <rsmp[+]>\n#> 2 formula_rand_forest   <tibble [1 × 4]> <opts[1]> <rsmp[+]>"
  },
  {
    "objectID": "slides/04-evaluating-models.html#evaluate-a-workflow-set-2",
    "href": "slides/04-evaluating-models.html#evaluate-a-workflow-set-2",
    "title": "4 - Evaluating models",
    "section": "Evaluate a workflow set",
    "text": "Evaluate a workflow set\n\nworkflow_set(list(latency ~ .), list(tree_spec, rf_spec)) %>%\n  workflow_map(\"fit_resamples\", resamples = frog_folds) %>%\n  rank_results()\n#> # A tibble: 4 × 9\n#>   wflow_id         .config .metric   mean std_err     n preprocessor model  rank\n#>   <chr>            <chr>   <chr>    <dbl>   <dbl> <int> <chr>        <chr> <int>\n#> 1 formula_rand_fo… Prepro… rmse    55.8    1.67      10 formula      rand…     1\n#> 2 formula_rand_fo… Prepro… rsq      0.371  0.0304    10 formula      rand…     1\n#> 3 formula_decisio… Prepro… rmse    59.6    2.31      10 formula      deci…     2\n#> 4 formula_decisio… Prepro… rsq      0.305  0.0342    10 formula      deci…     2\n\n\nLots more available with workflow sets, like collect_metrics(), autoplot() methods, and more!"
  },
  {
    "objectID": "slides/04-evaluating-models.html#your-turn-4",
    "href": "slides/04-evaluating-models.html#your-turn-4",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nWhen do you think a workflow set would be useful?\n\n\n\n03:00"
  },
  {
    "objectID": "slides/04-evaluating-models.html#the-final-fit",
    "href": "slides/04-evaluating-models.html#the-final-fit",
    "title": "4 - Evaluating models",
    "section": "The final fit ",
    "text": "The final fit \nSuppose that we are happy with our random forest model.\nLet’s verify our performance using the test set.\n\nWe’ve shown you fit() and predict() (+ augment()) but there is a shortcut:\n\n# frog_split has train + test info\nfinal_fit <- last_fit(rf_wflow, frog_split) \n\nfinal_fit\n#> # Resampling results\n#> # Manual resampling \n#> # A tibble: 1 × 6\n#>   splits            id               .metrics .notes   .predictions .workflow \n#>   <list>            <chr>            <list>   <list>   <list>       <list>    \n#> 1 <split [456/116]> train/test split <tibble> <tibble> <tibble>     <workflow>"
  },
  {
    "objectID": "slides/04-evaluating-models.html#what-is-in-final_fit",
    "href": "slides/04-evaluating-models.html#what-is-in-final_fit",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\ncollect_metrics(final_fit)\n#> # A tibble: 2 × 4\n#>   .metric .estimator .estimate .config             \n#>   <chr>   <chr>          <dbl> <chr>               \n#> 1 rmse    standard      57.1   Preprocessor1_Model1\n#> 2 rsq     standard       0.420 Preprocessor1_Model1\n\n\nThese are metrics computed with the test set"
  },
  {
    "objectID": "slides/04-evaluating-models.html#what-is-in-final_fit-1",
    "href": "slides/04-evaluating-models.html#what-is-in-final_fit-1",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\ncollect_predictions(final_fit)\n#> # A tibble: 116 × 5\n#>    id               .pred  .row latency .config             \n#>    <chr>            <dbl> <int>   <dbl> <chr>               \n#>  1 train/test split  43.3     1      22 Preprocessor1_Model1\n#>  2 train/test split 103.      3     106 Preprocessor1_Model1\n#>  3 train/test split  76.6     6      39 Preprocessor1_Model1\n#>  4 train/test split  43.0     8      50 Preprocessor1_Model1\n#>  5 train/test split  43.0    10      63 Preprocessor1_Model1\n#>  6 train/test split  42.8    14      25 Preprocessor1_Model1\n#>  7 train/test split  51.1    16      48 Preprocessor1_Model1\n#>  8 train/test split 163.     17      91 Preprocessor1_Model1\n#>  9 train/test split  50.7    32      11 Preprocessor1_Model1\n#> 10 train/test split 171.     33     109 Preprocessor1_Model1\n#> # … with 106 more rows\n\n\nThese are predictions for the test set"
  },
  {
    "objectID": "slides/04-evaluating-models.html#section-6",
    "href": "slides/04-evaluating-models.html#section-6",
    "title": "4 - Evaluating models",
    "section": "",
    "text": "collect_predictions(final_fit) %>%\n  ggplot(aes(latency, .pred)) + \n  geom_abline(lty = 2, col = \"deeppink4\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  coord_obs_pred()"
  },
  {
    "objectID": "slides/04-evaluating-models.html#what-is-in-final_fit-2",
    "href": "slides/04-evaluating-models.html#what-is-in-final_fit-2",
    "title": "4 - Evaluating models",
    "section": "What is in final_fit? ",
    "text": "What is in final_fit? \n\nextract_workflow(final_fit)\n#> ══ Workflow [trained] ════════════════════════════════════════════════\n#> Preprocessor: Formula\n#> Model: rand_forest()\n#> \n#> ── Preprocessor ──────────────────────────────────────────────────────\n#> latency ~ .\n#> \n#> ── Model ─────────────────────────────────────────────────────────────\n#> Ranger result\n#> \n#> Call:\n#>  ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n#> \n#> Type:                             Regression \n#> Number of trees:                  1000 \n#> Sample size:                      456 \n#> Number of independent variables:  4 \n#> Mtry:                             2 \n#> Target node size:                 5 \n#> Variable importance mode:         none \n#> Splitrule:                        variance \n#> OOB prediction error (MSE):       3128.496 \n#> R squared (OOB):                  0.3523713\n\n\nUse this for prediction on new data, like for deploying"
  },
  {
    "objectID": "slides/04-evaluating-models.html#your-turn-5",
    "href": "slides/04-evaluating-models.html#your-turn-5",
    "title": "4 - Evaluating models",
    "section": "Your turn",
    "text": "Your turn\n\nEnd of the day discussion!\nWhich model do you think you would decide to use?\nWhat surprised you the most?\nWhat is one thing you are looking forward to for tomorrow?\n\n\n\n05:00"
  },
  {
    "objectID": "slides/04-evaluating-models.html#why-choose-just-one-final_fit",
    "href": "slides/04-evaluating-models.html#why-choose-just-one-final_fit",
    "title": "4 - Evaluating models",
    "section": "Why choose just one final_fit? ",
    "text": "Why choose just one final_fit? \nModel stacks generate predictions that are informed by several models."
  },
  {
    "objectID": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-1",
    "href": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-1",
    "title": "4 - Evaluating models",
    "section": "Why choose just one final_fit? ",
    "text": "Why choose just one final_fit?"
  },
  {
    "objectID": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-2",
    "href": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-2",
    "title": "4 - Evaluating models",
    "section": "Why choose just one final_fit? ",
    "text": "Why choose just one final_fit?"
  },
  {
    "objectID": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-3",
    "href": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-3",
    "title": "4 - Evaluating models",
    "section": "Why choose just one final_fit? ",
    "text": "Why choose just one final_fit?"
  },
  {
    "objectID": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-4",
    "href": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-4",
    "title": "4 - Evaluating models",
    "section": "Why choose just one final_fit? ",
    "text": "Why choose just one final_fit?"
  },
  {
    "objectID": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-5",
    "href": "slides/04-evaluating-models.html#why-choose-just-one-final_fit-5",
    "title": "4 - Evaluating models",
    "section": "Why choose just one final_fit? ",
    "text": "Why choose just one final_fit?"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack",
    "href": "slides/04-evaluating-models.html#building-a-model-stack",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nlibrary(stacks)\n\n\nDefine candidate members\nInitialize a data stack object\nIteratively add candidate ensemble members to the data stack\nEvaluate how to combine their predictions\nFit candidate ensemble members with non-zero stacking coefficients\nPredict on new data!"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-1",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-1",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-2",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-2",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nDefine candidate members\n\nStart out with a linear regression:\n\nlr_res <- \n  # define model spec\n  linear_reg() %>%\n  set_mode(\"regression\") %>%\n  # add to workflow\n  workflow(preprocessor = latency ~ .) %>%\n  # fit to resamples\n  fit_resamples(frog_folds, control = stack_ctrl)"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-3",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-3",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nlr_res\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 × 5\n#>    splits           id     .metrics         .notes           .predictions     \n#>    <list>           <chr>  <list>           <list>           <list>           \n#>  1 <split [408/48]> Fold01 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [48 × 4]>\n#>  2 <split [408/48]> Fold02 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [48 × 4]>\n#>  3 <split [408/48]> Fold03 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [48 × 4]>\n#>  4 <split [409/47]> Fold04 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [47 × 4]>\n#>  5 <split [411/45]> Fold05 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [45 × 4]>\n#>  6 <split [412/44]> Fold06 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#>  7 <split [412/44]> Fold07 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#>  8 <split [412/44]> Fold08 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#>  9 <split [412/44]> Fold09 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#> 10 <split [412/44]> Fold10 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-4",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-4",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \nThen, a random forest:\n\nrf_res <- \n  # define model spec\n  rand_forest() %>%\n  set_mode(\"regression\") %>%\n  # add to workflow\n  workflow(preprocessor = latency ~ .) %>%\n  # fit to resamples\n  fit_resamples(frog_folds, control = stack_ctrl)"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-5",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-5",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nrf_res\n#> # Resampling results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 × 5\n#>    splits           id     .metrics         .notes           .predictions     \n#>    <list>           <chr>  <list>           <list>           <list>           \n#>  1 <split [408/48]> Fold01 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [48 × 4]>\n#>  2 <split [408/48]> Fold02 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [48 × 4]>\n#>  3 <split [408/48]> Fold03 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [48 × 4]>\n#>  4 <split [409/47]> Fold04 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [47 × 4]>\n#>  5 <split [411/45]> Fold05 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [45 × 4]>\n#>  6 <split [412/44]> Fold06 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#>  7 <split [412/44]> Fold07 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#>  8 <split [412/44]> Fold08 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#>  9 <split [412/44]> Fold09 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>\n#> 10 <split [412/44]> Fold10 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [44 × 4]>"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-6",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-6",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nInitialize a data stack object\n\n\n\nst <- stacks()\n\nst\n#> # A data stack with 0 model definitions and 0 candidate members."
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-7",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-7",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nIteratively add candidate ensemble members to the data stack\n\n\nst <- st %>%\n  add_candidates(lr_res) %>%\n  add_candidates(rf_res)\n\nst\n#> # A data stack with 2 model definitions and 2 candidate members:\n#> #   lr_res: 1 model configuration\n#> #   rf_res: 1 model configuration\n#> # Outcome: latency (numeric)"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-8",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-8",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nEvaluate how to combine their predictions\n\n\nst <- st %>%\n  blend_predictions()\n\nst\n#> # A tibble: 2 × 3\n#>   member     type        weight\n#>   <chr>      <chr>        <dbl>\n#> 1 rf_res_1_1 rand_forest  0.670\n#> 2 lr_res_1_1 linear_reg   0.318"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-9",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-9",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nFit candidate ensemble members with non-zero stacking coefficients\n\n\nst <- st %>%\n  fit_members()\n\nst\n#> # A tibble: 2 × 3\n#>   member     type        weight\n#>   <chr>      <chr>        <dbl>\n#> 1 rf_res_1_1 rand_forest  0.670\n#> 2 lr_res_1_1 linear_reg   0.318"
  },
  {
    "objectID": "slides/04-evaluating-models.html#building-a-model-stack-10",
    "href": "slides/04-evaluating-models.html#building-a-model-stack-10",
    "title": "4 - Evaluating models",
    "section": "Building a model stack ",
    "text": "Building a model stack \n\nPredict on new data!\n\n\n\nfrog_test %>%\n  select(latency) %>%\n  bind_cols(predict(st, frog_test)) %>%\n  ggplot(aes(latency, .pred)) + \n  geom_abline(lty = 2, \n              col = \"deeppink4\", \n              size = 1.5) +\n  geom_point(alpha = 0.5) +\n  coord_obs_pred()\n\n\n\n\n\n\n\n\n\n\n\n\nhttps://workshops.tidymodels.org"
  }
]